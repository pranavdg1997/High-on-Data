{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "#importing basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Importing pytorch functions and modules\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchtext import data\n",
    "from sklearn.metrics import *\n",
    "\n",
    "#Import NLP libraries\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "#Setting random seed for reproducibility\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|,;]^a-zA-Z#')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    \n",
    "  \n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                    \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                    \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \n",
    "                    \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \n",
    "                    \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \n",
    "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\n",
    "                    \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \n",
    "                    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \n",
    "                    \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                    \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \n",
    "                    \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\",\n",
    "                    \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \n",
    "                    \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \n",
    "                    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \n",
    "                    \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \n",
    "                    \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \n",
    "                    \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\",\n",
    "                    \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                    \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                    \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \n",
    "                    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "# Usage\n",
    "replace_contractions(\"this's a text with contraction\")\n",
    "    \n",
    "\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified, pre-processed tokens\n",
    "    \"\"\"\n",
    "#     text = # Remove long spaces and combine\n",
    "#     text = # lowercase text\n",
    "#     text = # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "#     text = # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "#     text = # delete stopwords from text\n",
    "    \n",
    "    text = ' '.join(text.split())\n",
    "    #print(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    #print(text)\n",
    "    text = ' '.join(word for word in text.split() if not(word.startswith('@')))\n",
    "    text = ' '.join(word for word in text.split() if not(word.startswith('http')))\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    #print(text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    #print(text)\n",
    "    #print(text)\n",
    "    #text = ' '.join([word for word in text.split() if word not in STOPWORDS]) # delete stopwors from text\n",
    "    #print(text)\n",
    "    text = ' '.join([word for word in text.split() if len(word)> 3]) # delete short words\n",
    "    text = ' '.join([word.replace(\"#\",'') for word in text.split() if len(word)> 3])\n",
    "    text = replace_contractions(text)\n",
    "    if(len(text.split())==0):\n",
    "      text = \"blank\"\n",
    "\n",
    "    return text.split()\n",
    "  \n",
    "def to_float_array(str):\n",
    "  str = ' '.join(str.split())\n",
    "  str = str.replace(\"[\",\"\")\n",
    "  str = str.replace(\"]\",\"\")\n",
    "  str = np.array(str.split()).astype(np.float)\n",
    "  return(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>drug_user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.172183e+18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Again? Again? Codeine no dey quick clear for b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.172175e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>At least he doesn’t play Codeine, though.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.171842e+18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yeah, have you tried oxy tho? Or Vicodin? Or t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.170154e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>At the store currently, will be doing an IRL s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.172236e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>They are also the organizers of an upcoming ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  drug_user                                              tweet\n",
       "0  1.172183e+18        1.0  Again? Again? Codeine no dey quick clear for b...\n",
       "1  1.172175e+18        0.0          At least he doesn’t play Codeine, though.\n",
       "2  1.171842e+18        1.0  Yeah, have you tried oxy tho? Or Vicodin? Or t...\n",
       "3  1.170154e+18        0.0  At the store currently, will be doing an IRL s...\n",
       "4  1.172236e+18        0.0  They are also the organizers of an upcoming ev..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_tweets = pd.read_csv(\"labelled_tweets_twint.csv\")[[\"id\",\"drug_user\",\"tweet\"]].dropna()\n",
    "scraped_tweets = pd.read_csv(\"scraped_tweets_twint.csv\")[[\"id\",\"tweet\"]]\n",
    "labelled_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 493 entries, 0 to 4007\n",
      "Data columns (total 3 columns):\n",
      "id           493 non-null float64\n",
      "drug_user    493 non-null float64\n",
      "tweet        493 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 15.4+ KB\n"
     ]
    }
   ],
   "source": [
    "labelled_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data,val_data,_,_ = train_test_split(labelled_tweets,labelled_tweets[\"drug_user\"],\n",
    "                                           stratify=labelled_tweets[\"drug_user\"].values,test_size=0.25)\n",
    "test_data = scraped_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\",index=False)\n",
    "test_data.to_csv(\"test_data.csv\",index=False)\n",
    "val_data.to_csv(\"val_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TWEET vocabulary:  2064\n",
      "Unique tokens in LABEL vocabulary:  2\n"
     ]
    }
   ],
   "source": [
    "TWEET = data.Field(sequential=True, tokenize=custom_tokenizer, lower=True,include_lengths = True)\n",
    "LABEL = data.LabelField(sequential=False, use_vocab=True,pad_token=None,unk_token=None)\n",
    "\n",
    "\n",
    "fields = [(None, None), ('l', LABEL), ('t', TWEET)]\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = '',\n",
    "                                        train = 'train_data.csv',\n",
    "                                        validation = 'val_data.csv',\n",
    "                                        test = 'test_data.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")\n",
    "\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TWEET.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n",
    "print(\"Unique tokens in TWEET vocabulary: \",len(TWEET.vocab))\n",
    "print(\"Unique tokens in LABEL vocabulary: \",len(LABEL.vocab))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key=lambda x:len(x.t),\n",
    "    sort=True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)#,enforce_sorted=False)\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))       \n",
    "        return torch.sigmoid(self.fc(hidden.squeeze()))\n",
    "      \n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    y_true = y.detach().cpu()\n",
    "    y_pred = torch.round(preds).detach().cpu()\n",
    "    acc = accuracy_score(y_true,y_pred)\n",
    "    return acc\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    #print(0)\n",
    "    model.train()\n",
    "    #print(1)\n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.t\n",
    "        #print(2)\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        \n",
    "        loss = criterion(predictions.type(torch.float), batch.l.type(torch.float))\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.l)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    #print(\"training done\")    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.t\n",
    "\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions.type(torch.float), batch.l.type(torch.float))\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.l)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    #print(\"evaluation done\")\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "  \n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 837,441 trainable parameters\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.696 | Train Acc: 45.80%\n",
      "\t Val. Loss: 0.692 |  Val. Acc: 51.88%\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.689 | Train Acc: 55.08%\n",
      "\t Val. Loss: 0.686 |  Val. Acc: 58.33%\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.684 | Train Acc: 59.50%\n",
      "\t Val. Loss: 0.681 |  Val. Acc: 59.90%\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.677 | Train Acc: 61.85%\n",
      "\t Val. Loss: 0.676 |  Val. Acc: 63.02%\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.672 | Train Acc: 62.11%\n",
      "\t Val. Loss: 0.671 |  Val. Acc: 63.80%\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.668 | Train Acc: 61.85%\n",
      "\t Val. Loss: 0.667 |  Val. Acc: 63.80%\n",
      "Overfitting, stopping after this epoch\n",
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.665 | Train Acc: 62.63%\n",
      "\t Val. Loss: 0.663 |  Val. Acc: 63.80%\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(TWEET.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "LR = 0.0001\n",
    "PAD_IDX = TWEET.vocab.stoi[TWEET.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX).to(device)\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "pretrained_embeddings = TWEET.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TWEET.vocab.stoi[TWEET.unk_token]\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),lr=LR)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "N_EPOCHS = 200\n",
    "EARLY_STOPPING_ROUNDS = 2\n",
    "curr_rounds = 0\n",
    "best_valid_acc = (-1)*float('inf')\n",
    "epoch = 0\n",
    "overfitting = False\n",
    "\n",
    "while((epoch < N_EPOCHS)&(overfitting==False)):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    if(valid_acc > best_valid_acc):\n",
    "        best_valid_acc = valid_acc\n",
    "        curr_rounds = 0\n",
    "    else:\n",
    "        curr_rounds +=1\n",
    "        if(curr_rounds==EARLY_STOPPING_ROUNDS):\n",
    "            overfitting=True\n",
    "            print(\"Overfitting, stopping after this epoch\")\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    \n",
    "    if(epoch%10==0):\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok for tok in custom_tokenizer(sentence)]\n",
    "    indexed = [TWEET.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = model(tensor, length_tensor)\n",
    "    prob = prediction.item()\n",
    "    return(round(prob,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_tweets[\"drug_use_probablity\"] = scraped_tweets[\"tweet\"].apply(lambda x:predict_sentiment(model,x))\n",
    "scraped_tweets.to_csv(\"drug_use_redictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff711b80400>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.distplot(scraped_tweets[\"drug_use_probablity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
